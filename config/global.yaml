global_args:
  trainer_backend: pl
  enable_deepspeed: false
  enable_ptv2: false
  enable_lora: true
  load_in_bit: 0
  config_merge: {}
  pre_seq_len: 32  # p-tuning-v2 参数 , None 禁用p-tuning-v2
  prefix_projection: False  # p-tuning-v2 参数
  num_layers_freeze: -1  # 非lora,非p-tuning 模式 ， <= config.json num_layers
  # 模型权重 ， 对应 config.constant_map.py
  model_name: glm-4-9b-chat

  # one of auto 16 bf16 32
  precision: auto
  quantization_config:
    load_in_8bit: false
    load_in_4bit: false
    llm_int8_threshold: 6.0
    llm_int8_has_fp16_weight: false
    bnb_4bit_compute_dtype: float16  # one of float16  bfloat16 float32
    bnb_4bit_use_double_quant: true
    bnb_4bit_quant_type: nf4


global_models_mapper: 
    glm-4-9b-chat:
        model_type: chatglm
        model_name_or_path: /data/nlp/pre_models/torch/glm4/glm-4-9b-chat

    glm-4-9b-chat-1m:
      model_type: chatglm
      model_name_or_path: /data/nlp/pre_models/torch/glm4/glm-4-9b-chat-1m
